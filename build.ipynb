{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data for Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function for checking memory usage of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_memory_usage(data):\n",
    "    \"\"\" Takes DataFrame as input and returns memory usage statistics. \n",
    "    \"\"\"\n",
    "    print ''\n",
    "    print 'Checking memory usage statistics... '\n",
    "    print(data.info(memory_usage=True))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(): \n",
    "    \"\"\" Loads and returns competition data, including modified clients and products data.\n",
    "    \"\"\"\n",
    "    # Set work directory\n",
    "    os.chdir('D:/OneDrive/Documents/Kaggle/Grupo Bimbo Inventory Demand/data')      \n",
    "    \n",
    "    # Load data efficiently to use less RAM\n",
    "    train_types = {\n",
    "                    'Semana': np.uint8, 'Agencia_ID': np.uint16, 'Canal_ID': np.uint8\n",
    "                    ,'Ruta_SAK': np.uint16, 'Cliente_ID': np.uint32, 'Producto_ID': np.uint16\n",
    "                    ,'Demanda_uni_equil': np.uint16\n",
    "                    }   \n",
    "         \n",
    "    test_types =  {\n",
    "                    'Semana': np.uint8, 'Agencia_ID': np.uint16, 'Canal_ID': np.uint8\n",
    "                    ,'Ruta_SAK': np.uint16, 'Cliente_ID': np.uint32, 'Producto_ID': np.uint16\n",
    "                    }\n",
    "                    \n",
    "    product_types = {'Producto_ID': np.uint16, 'weight': np.float32, 'pieces': np.float32\n",
    "                    , 'weight_per_piece': np.float32, 'short_product_name': np.object\n",
    "                    }\n",
    "    \n",
    "    train = pd.read_csv(\"train.csv\", sep = \",\", usecols = train_types.keys(), dtype = train_types) \n",
    "    test = pd.read_csv(\"test.csv\", sep = \",\", usecols = test_types.keys(), dtype = test_types)\n",
    "    \n",
    "    clients = pd.read_csv(\"cliente_tabla_modified.csv\", sep = \",\") \n",
    "    products = pd.read_csv(\"producto_tabla_modified.csv\", sep = \",\", usecols = product_types.keys(), dtype = product_types) \n",
    "        \n",
    "    # Return data\n",
    "    return train, test, clients, products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data...\n",
      "Complete!\n",
      "\n",
      "\n",
      "Checking memory usage statistics... \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74180464 entries, 0 to 74180463\n",
      "Data columns (total 7 columns):\n",
      "Semana               uint8\n",
      "Agencia_ID           uint16\n",
      "Canal_ID             uint8\n",
      "Ruta_SAK             uint16\n",
      "Cliente_ID           uint32\n",
      "Producto_ID          uint16\n",
      "Demanda_uni_equil    uint16\n",
      "dtypes: uint16(4), uint32(1), uint8(2)\n",
      "memory usage: 990.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print \"1. Loading data...\"\n",
    "train, test, clients, products = load_data()\n",
    "print \"Complete!\"\n",
    "print ''\n",
    "check_memory_usage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_data(train, test, clients, products):\n",
    "    \"\"\" Merges client and product data with train and test data. \n",
    "        Returns modified train and test data.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Merge product information\n",
    "    train = train.merge(products, how = 'left', on = ['Producto_ID'])\n",
    "    test = test.merge(products, how = 'left', on = ['Producto_ID'])\n",
    "\n",
    "    # Merge cliente information\n",
    "    train = train.merge(clients.ix[:, ['Cliente_ID', 'Client_Type']], how = 'left', on = ['Cliente_ID'])\n",
    "    test = test.merge(clients.ix[:, ['Cliente_ID', 'Client_Type']], how = 'left', on = ['Cliente_ID'])         \n",
    "\n",
    "    return train, test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Merging data...\n",
      "Complete!\n",
      "\n",
      "\n",
      "Checking memory usage statistics... \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74180464 entries, 0 to 74180463\n",
      "Data columns (total 12 columns):\n",
      "Semana                uint8\n",
      "Agencia_ID            uint16\n",
      "Canal_ID              uint8\n",
      "Ruta_SAK              uint16\n",
      "Cliente_ID            uint32\n",
      "Producto_ID           uint16\n",
      "Demanda_uni_equil     uint16\n",
      "weight                float32\n",
      "pieces                float32\n",
      "weight_per_piece      float32\n",
      "short_product_name    object\n",
      "Client_Type           object\n",
      "dtypes: float32(3), object(2), uint16(4), uint32(1), uint8(2)\n",
      "memory usage: 3.5+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print \"2. Merging data...\"\n",
    "train, test = merge_data(train, test, clients, products) \n",
    "print \"Complete!\"\n",
    "print \"\"\n",
    "check_memory_usage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time series lag variables to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_time_series_features(train, test):\n",
    "    \"\"\" Takes train and test data as inputs. \n",
    "        Adds lagged adjusted demand variables to the data periods t-2, t-3, t-4, and t-5.\n",
    "        Returns modified data. \n",
    "    \"\"\"\n",
    "    # Add lagged time series variables to train/test\n",
    "    # Groups by (Cliente_ID, Producto_ID)\n",
    "    for i in range(1, 6):\n",
    "        # Add tminus to train\n",
    "        columns = ['Semana', 'Cliente_ID', 'Producto_ID', 'Demanda_uni_equil']       \n",
    "        train_tminus = train.ix[:, columns]\n",
    "        train_tminus = train_tminus.rename(columns = {'Demanda_uni_equil': 'Demanda_uni_equil_tminus' + str(i)})\n",
    "        train_tminus['Semana'] = train_tminus['Semana'] + i\n",
    "        columns.remove('Demanda_uni_equil')\n",
    "        train_tminus = pd.DataFrame({'Demanda_uni_equil_tminus' + str(i) : train_tminus.groupby(columns)['Demanda_uni_equil_tminus' + str(i)].mean()}).reset_index()         \n",
    "        \n",
    "        train = train.merge(train_tminus, how = 'left', on = ['Semana', 'Cliente_ID', 'Producto_ID'])   \n",
    "        train['Demanda_uni_equil_tminus' + str(i)] = train['Demanda_uni_equil_tminus' + str(i)].astype(np.float16)\n",
    "                \n",
    "        # Add tminus for Semana == 10\n",
    "        columns = ['Semana', 'Cliente_ID', 'Producto_ID', 'Demanda_uni_equil_tminus' + str(i)]\n",
    "        test = test.merge(train_tminus.ix[train_tminus['Semana'] == 10, columns], how = 'left', on = ['Semana', 'Cliente_ID', 'Producto_ID'])\n",
    "        test['Demanda_uni_equil_tminus' + str(i)] = test['Demanda_uni_equil_tminus' + str(i)].astype(np.float16)     \n",
    "    \n",
    "        # Add tminus for Semana == 11\n",
    "        if(i != 1):\n",
    "            test = test.merge(train_tminus.ix[train_tminus['Semana'] == 11, columns], how = 'left', on = ['Semana', 'Cliente_ID', 'Producto_ID']) \n",
    "            test = test.rename(columns = {'Demanda_uni_equil_tminus' + str(i) + '_x': 'Demanda_uni_equil_tminus' + str(i)})\n",
    "            test.ix[test['Semana'] == 11, 'Demanda_uni_equil_tminus' + str(i)] = test.ix[test['Semana'] == 11, 'Demanda_uni_equil_tminus' + str(i) + '_y']\n",
    "            test = test.drop('Demanda_uni_equil_tminus' + str(i) + '_y', axis = 1)\n",
    "            test['Demanda_uni_equil_tminus' + str(i)] = test['Demanda_uni_equil_tminus' + str(i)].astype(np.float16)\n",
    "        \n",
    "        # Replace null values with zeros\n",
    "        train.ix[train['Demanda_uni_equil_tminus' + str(i)].isnull(), 'Demanda_uni_equil_tminus' + str(i)] = 0\n",
    "        test.ix[test['Demanda_uni_equil_tminus' + str(i)].isnull(), 'Demanda_uni_equil_tminus' + str(i)] = 0    \n",
    "            \n",
    "    return train, test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Adding time series features...\n"
     ]
    }
   ],
   "source": [
    "print \"3. Adding time series features...\"\n",
    "train, test = add_time_series_features(train, test)  \n",
    "print \"Complete!\"\n",
    "print \"\"\n",
    "check_memory_usage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add mean weekly frequency variables for categorical id variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_mean_freq_by_id(train, test):\n",
    "    \"\"\" Takes train and test data as inputs. \n",
    "        Adds mean of frequencies of different id features by week (semana).\n",
    "        Returns train and test data.\n",
    "    \"\"\"\n",
    "    columns =  ['Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Cliente_ID', 'Producto_ID', 'short_product_name', 'Client_Type'] \n",
    "    for column in columns:\n",
    "        \n",
    "        # Create mean of weekly id counts\n",
    "        train_counts = pd.DataFrame({column + '_count' : train[[column, 'Semana']].groupby([column, 'Semana']).size()}).reset_index()\n",
    "        test_counts = pd.DataFrame({column + '_count' : test[[column, 'Semana']].groupby([column, 'Semana']).size()}).reset_index()\n",
    "        counts = train_counts.append(test_counts)      \n",
    "        counts = pd.DataFrame({column + '_count' : counts.groupby([column])[column + '_count'].mean()}).reset_index()\n",
    "        counts[column + '_count'] = counts[column + '_count'].astype(np.float32) \n",
    "\n",
    "        # Merge with train and test data\n",
    "        train = train.merge(counts, how = 'left', on = column)    \n",
    "        test = test.merge(counts, how = 'left', on = column)  \n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Adding id frequency variables... \n",
      "Complete!\n",
      "\n",
      "\n",
      "Checking memory usage statistics... \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74180464 entries, 0 to 74180463\n",
      "Data columns (total 19 columns):\n",
      "Semana                      uint8\n",
      "Agencia_ID                  uint16\n",
      "Canal_ID                    uint8\n",
      "Ruta_SAK                    uint16\n",
      "Cliente_ID                  uint32\n",
      "Producto_ID                 uint16\n",
      "Demanda_uni_equil           uint16\n",
      "weight                      float32\n",
      "pieces                      float32\n",
      "weight_per_piece            float32\n",
      "short_product_name          object\n",
      "Client_Type                 object\n",
      "Agencia_ID_count            float32\n",
      "Canal_ID_count              float32\n",
      "Ruta_SAK_count              float32\n",
      "Cliente_ID_count            float32\n",
      "Producto_ID_count           float32\n",
      "short_product_name_count    float32\n",
      "Client_Type_count           float32\n",
      "dtypes: float32(10), object(2), uint16(4), uint32(1), uint8(2)\n",
      "memory usage: 5.4+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#print train.columns\n",
    "print \"4. Adding id frequency variables... \"\n",
    "train, test = add_mean_freq_by_id(train, test)\n",
    "print \"Complete!\"\n",
    "print ''\n",
    "check_memory_usage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_labels(train, test, threshold): \n",
    "    \"\"\" Converts categorical features to integers in train and test data.\n",
    "        Groups values in categorical features appearing less than threshold into a separate category.\n",
    "        Returns train and test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify columns for label encoding\n",
    "    columns = list(train.columns[train.dtypes == 'object'])\n",
    "       \n",
    "    # Return data if no columns identified   \n",
    "    if(len(columns) == 0):\n",
    "        return train, test\n",
    "       \n",
    "    # Transform columns\n",
    "    for column in columns: \n",
    "        \n",
    "        # Filter data\n",
    "        classes = train[column].unique()\n",
    "        counts = train[column].value_counts()\n",
    "        counts_classes = counts.index[counts <= threshold]\n",
    "        \n",
    "        # Set classes under threshold to 'identific'\n",
    "        train.ix[train[column].isin(counts_classes), column] = 'identific'        \n",
    "        test.ix[test[column].isin(counts_classes), column] = 'identific'          \n",
    "        \n",
    "        # Classes in test not in train sent to 'identific'\n",
    "        test.ix[test[column].isin(classes) == False, column] = 'identific'\n",
    "        \n",
    "        # Perform label encoding\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train[column])\n",
    "        train[column] = le.transform(train[column]).astype(np.uint32)\n",
    "        test[column] = le.transform(test[column]).astype(np.uint32)\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"5. Encoding labels in data...\"\n",
    "train, test = encode_labels(train, test, threshold = 5)\n",
    "print \"Complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove data before Week 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Shape Before (train): \" + str(train.shape)\n",
    "train = train[train['Semana'] > 5]  \n",
    "train = train.reset_index(drop=True)\n",
    "print \"Shape After (train): \" + str(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorder columns in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "            'Semana', 'Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Cliente_ID', 'Producto_ID'\n",
    "            , 'Client_Type', 'short_product_name' \n",
    "            , 'weight', 'pieces', 'weight_per_piece'\n",
    "            , 'Demanda_uni_equil', 'Demanda_uni_equil_tminus1', 'Demanda_uni_equil_tminus2'\n",
    "            , 'Demanda_uni_equil_tminus3', 'Demanda_uni_equil_tminus4', 'Demanda_uni_equil_tminus5'\n",
    "            , 'Agencia_ID_count', 'Canal_ID_count', 'Ruta_SAK_count', 'Cliente_ID_count'\n",
    "            , 'Producto_ID_count', 'Client_Type_count'\n",
    "          ]\n",
    "\n",
    "train = train.reindex(columns = columns)\n",
    "columns.remove('Demanda_uni_equil')\n",
    "test = test.reindex(columns = columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_memory_usage(train)\n",
    "train.to_csv(\"train_modified.csv\", index = False, header = True)\n",
    "test.to_csv(\"test_modified.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
